{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from DeepEverest import DeepEverest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data for the demonstration (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST('../data', train=True, download=True,\n",
    "                    transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])), batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(datasets.MNIST('../data', train=False, \n",
    "                        transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])), batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct a model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(10, 20, kernel_size=5),\n",
    "            nn.Dropout2d(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(320, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(50, 10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "    def forward(self, inputs):\n",
    "        return self.model(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare datasets, and construct DeepEverest class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10398/2494629665.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dataset = torch.tensor(data)\n",
      "/tmp/ipykernel_10398/2494629665.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  dataset_labels = torch.tensor(data_set)\n"
     ]
    }
   ],
   "source": [
    "dataset = torch.tensor([])\n",
    "dataset_labels = torch.tensor([])\n",
    "for num, (data, data_set) in enumerate(test_loader):\n",
    "    if num == 0:\n",
    "        dataset = torch.tensor(data)\n",
    "        dataset_labels = torch.tensor(data_set)\n",
    "    else:\n",
    "        dataset = torch.cat((dataset, data), 0)\n",
    "        dataset_labels = torch.cat((dataset_labels, data_set), 0)\n",
    "model = Net()\n",
    "lib_file = \"index/build/lib.linux-x86_64-3.8/deepeverst_index.cpython-38-x86_64-linux-gnu.so\"\n",
    "model = DeepEverest(model, True, lib_file, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct a new pytorch network, and construct the network into the DeepEverest API class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model = DeepEverest(model, True, lib_file, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load a pretrained weight as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('mnist.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### print out all the layer outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': <torch.utils.hooks.RemovableHandle at 0x7f09eaedc550>,\n",
       " 'model': <torch.utils.hooks.RemovableHandle at 0x7f09eaedc6a0>,\n",
       " 'model.0': <torch.utils.hooks.RemovableHandle at 0x7f09eaedc2b0>,\n",
       " 'model.1': <torch.utils.hooks.RemovableHandle at 0x7f09eaedc790>,\n",
       " 'model.2': <torch.utils.hooks.RemovableHandle at 0x7f09eaedc7f0>,\n",
       " 'model.3': <torch.utils.hooks.RemovableHandle at 0x7f09eaedc910>,\n",
       " 'model.4': <torch.utils.hooks.RemovableHandle at 0x7f09eaedc5e0>,\n",
       " 'model.5': <torch.utils.hooks.RemovableHandle at 0x7f09eaedc670>,\n",
       " 'model.6': <torch.utils.hooks.RemovableHandle at 0x7f09eaedc730>,\n",
       " 'model.7': <torch.utils.hooks.RemovableHandle at 0x7f09eaedca30>,\n",
       " 'model.8': <torch.utils.hooks.RemovableHandle at 0x7f09eaedc0a0>,\n",
       " 'model.9': <torch.utils.hooks.RemovableHandle at 0x7f0a4b4a0070>,\n",
       " 'model.10': <torch.utils.hooks.RemovableHandle at 0x7f0a4b4a0100>,\n",
       " 'model.11': <torch.utils.hooks.RemovableHandle at 0x7f0a4b4a01f0>,\n",
       " 'model.12': <torch.utils.hooks.RemovableHandle at 0x7f09e868b3a0>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 2, 1,  ..., 4, 5, 6])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model\n",
      "model.0\n",
      "model.1\n",
      "model.2\n",
      "model.3\n",
      "model.4\n",
      "model.5\n",
      "model.6\n",
      "model.7\n",
      "model.8\n",
      "model.9\n",
      "model.10\n",
      "model.11\n",
      "model.12\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.get_model().named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose one of the layer names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'model', 'model.0', 'model.1', 'model.2', 'model.3', 'model.4', 'model.5', 'model.6', 'model.7', 'model.8', 'model.9', 'model.10', 'model.11', 'model.12']\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "all_layer_names = model.get_all_layer_names()\n",
    "print(all_layer_names)\n",
    "layer_name = \"model.2\"\n",
    "layer_id = all_layer_names.index(layer_name)\n",
    "print(layer_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following two lines are demonstration purpose, this is not needed in use of DeepEverest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_result = model.get_layer_results_by_layer_id(layer_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10, 12, 12)\n"
     ]
    }
   ],
   "source": [
    "print(layer_result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Give top-k activation neurons of image 659 as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(15.056664, (4, 4, 6)), (14.274166, (4, 5, 6)), (13.664486, (4, 6, 6)), (13.554054, (4, 3, 6)), (13.502932, (4, 8, 6)), (13.477571, (4, 9, 6)), (13.340709, (1, 11, 6)), (13.27995, (4, 4, 7)), (13.197538, (1, 5, 3)), (13.188957, (4, 3, 7)), (13.090613, (1, 10, 6)), (12.774042, (1, 5, 4)), (12.733601, (4, 2, 6)), (12.522223, (4, 7, 6)), (12.089676, (4, 5, 7)), (11.97962, (1, 11, 7)), (11.603155, (4, 8, 5)), (11.496715, (4, 2, 7)), (11.474282, (0, 3, 7)), (11.457584, (1, 4, 4))]]\n"
     ]
    }
   ],
   "source": [
    "topk_activations = model.get_topk_activations_given_images([659], layer_name, 20)\n",
    "print(topk_activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify the results are correct (same) by brute force. This is for demonstration only, no need when using DeepEverest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor(15.0567), (4, 4, 6)), (tensor(14.2742), (4, 5, 6)), (tensor(13.6645), (4, 6, 6)), (tensor(13.5541), (4, 3, 6)), (tensor(13.5029), (4, 8, 6)), (tensor(13.4776), (4, 9, 6)), (tensor(13.3407), (1, 11, 6)), (tensor(13.2800), (4, 4, 7)), (tensor(13.1975), (1, 5, 3)), (tensor(13.1890), (4, 3, 7)), (tensor(13.0906), (1, 10, 6)), (tensor(12.7740), (1, 5, 4)), (tensor(12.7336), (4, 2, 6)), (tensor(12.5222), (4, 7, 6)), (tensor(12.0897), (4, 5, 7)), (tensor(11.9796), (1, 11, 7)), (tensor(11.6032), (4, 8, 5)), (tensor(11.4967), (4, 2, 7)), (tensor(11.4743), (0, 3, 7)), (tensor(11.4576), (1, 4, 4))]\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "image_samples = []\n",
    "for image_sample_id in [659]:\n",
    "    image_samples.append(dataset[image_sample_id])\n",
    "image_samples = torch.stack(image_samples)\n",
    "layer_result_image_samples = model.get_layer_result_by_layer_name(image_samples, layer_name)\n",
    "brute_force = []\n",
    "for i in range(layer_result_image_samples.shape[1]):\n",
    "    for j in range(layer_result_image_samples.shape[2]):\n",
    "        for k in range(layer_result_image_samples.shape[3]):\n",
    "            brute_force.append((layer_result_image_samples[0, i, j, k], (i, j, k)))\n",
    "sorted_array = sorted(brute_force, key=lambda k:k[0], reverse=True)\n",
    "print(sorted_array[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Neuron groups (Choose the top-3 neurons for demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 4, 6), (4, 5, 6), (4, 6, 6), (4, 3, 6), (4, 8, 6), (4, 9, 6), (1, 11, 6), (4, 4, 7), (1, 5, 3), (4, 3, 7), (1, 10, 6), (1, 5, 4), (4, 2, 6), (4, 7, 6), (4, 5, 7), (1, 11, 7), (4, 8, 5), (4, 2, 7), (0, 3, 7), (1, 4, 4)]\n"
     ]
    }
   ],
   "source": [
    "from NeuronGroup import *\n",
    "image_sample_id = 659\n",
    "topk_activations_neurons = [x[1] for x in topk_activations[0]]\n",
    "print(topk_activations_neurons)\n",
    "neuron_group = NeuronGroup(model.get_model(), layer_id, neuron_idx_list=topk_activations_neurons[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query the top 20 closest images with respect to the top 3 neurons found in the last step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 659, size of neuron group 3\n",
      "threshold: 0.10146905481815338, max in answer: 1.40303635597229, images run: 67\n",
      "threshold: 0.20118562877178192, max in answer: 1.1438370943069458, images run: 132\n",
      "threshold: 0.2788737714290619, max in answer: 0.9198803901672363, images run: 196\n",
      "threshold: 0.42958271503448486, max in answer: 0.7807649374008179, images run: 260\n",
      "threshold: 0.5854843854904175, max in answer: 0.7519282102584839, images run: 325\n",
      "threshold: 0.7778107523918152, max in answer: 0.7440550923347473, images run: 389\n",
      "======================= NTA exited =======================\n"
     ]
    }
   ],
   "source": [
    "top_k, exit_msg = model.answer_query_with_guarantee(layer_id, image_sample_id, 20, neuron_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print out distance and corresponding image indices, the distance are the absolute value of the first element, and the image id are the second element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query result (distance from the input image, image ids) array is:\n",
      "[(-0.7440551, 2915), (-0.7409354, 6074), (-0.6970588, 8109), (-0.6478751, 7822), (-0.6055464, 3611), (-0.58405477, 6118), (-0.5718313, 4011), (-0.53731173, 8100), (-0.52412087, 4097), (-0.5215469, 4861), (-0.46935377, 6988), (-0.44762346, 6096), (-0.4275496, 8048), (-0.4268946, 7783), (-0.42228025, 1909), (-0.41333342, 3229), (-0.3712188, 1480), (-0.23766346, 8679), (-0.113409005, 8112), (0.0, 659)]\n",
      "termination: images run: 389\n"
     ]
    }
   ],
   "source": [
    "print(\"The query result (distance from the input image, image ids) array is:\")\n",
    "print(top_k)\n",
    "print(exit_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify the results are correct (same) by brute force. This is for demonstration only, no need when using DeepEverest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10, 12, 12)\n",
      "[(4, 4, 6), (4, 5, 6), (4, 6, 6)]\n",
      "[15.056664 14.274166 13.664486]\n",
      "\n",
      "The query result (distance from the input image, image ids) array by brute force is:\n",
      "[(0.7440551, 2915), (0.7409354, 6074), (0.6970588, 8109), (0.6478751, 7822), (0.6055464, 3611), (0.58405477, 6118), (0.5718313, 4011), (0.53731173, 8100), (0.52412087, 4097), (0.5215469, 4861), (0.46935377, 6988), (0.44762346, 6096), (0.4275496, 8048), (0.4268946, 7783), (0.42228025, 1909), (0.41333342, 3229), (0.3712188, 1480), (0.23766346, 8679), (0.113409005, 8112), (0.0, 659)]\n"
     ]
    }
   ],
   "source": [
    "layer_result = model.get_layer_results_by_layer_id(layer_id)\n",
    "print(layer_result.shape)\n",
    "print(topk_activations_neurons[:3])\n",
    "search_target = np.array([layer_result[659][(4, 4, 6)], layer_result[659][(4, 5, 6)], layer_result[659][(4, 6, 6)]])\n",
    "print(search_target)\n",
    "result_array = []\n",
    "for i in range(len(dataset)):\n",
    "    number = np.array([layer_result[i][(4, 4, 6)], layer_result[i][(4, 5, 6)], layer_result[i][(4, 6, 6)]])\n",
    "    distance = np.sqrt(np.sum((search_target - number) * (search_target - number)))\n",
    "    result_array.append((distance, i))\n",
    "result_array = sorted(result_array, key=lambda k: k[0], reverse=True)\n",
    "print()\n",
    "print(\"The query result (distance from the input image, image ids) array by brute force is:\")\n",
    "print(result_array[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 321, 810]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_ids = [1, 0, 321, 810]\n",
    "image_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This tool is capable of search group of images in one query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_activations = model.get_topk_activations_given_images(image_ids, layer_name, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(15.404506, (1, 10, 6)),\n",
       "  (14.740844, (1, 10, 9)),\n",
       "  (14.725686, (1, 10, 5)),\n",
       "  (14.658377, (1, 10, 4)),\n",
       "  (14.074226, (1, 10, 7)),\n",
       "  (14.018891, (1, 10, 10)),\n",
       "  (13.745972, (1, 10, 3)),\n",
       "  (13.607746, (1, 2, 5)),\n",
       "  (13.291188, (1, 10, 8)),\n",
       "  (12.143644, (1, 2, 4)),\n",
       "  (11.776539, (4, 2, 6)),\n",
       "  (11.771938, (4, 6, 4)),\n",
       "  (11.722886, (4, 8, 3)),\n",
       "  (11.716561, (1, 1, 5)),\n",
       "  (11.585614, (4, 3, 6)),\n",
       "  (11.531162, (4, 7, 3)),\n",
       "  (11.222839, (4, 5, 4)),\n",
       "  (11.1286335, (4, 4, 5)),\n",
       "  (11.101066, (1, 10, 11)),\n",
       "  (11.002071, (4, 5, 5))],\n",
       " [(14.003622, (1, 4, 4)),\n",
       "  (13.753479, (1, 4, 5)),\n",
       "  (13.233683, (1, 4, 3)),\n",
       "  (13.210785, (1, 4, 6)),\n",
       "  (12.756104, (1, 4, 7)),\n",
       "  (10.772835, (4, 11, 4)),\n",
       "  (10.763884, (4, 10, 5)),\n",
       "  (10.652996, (4, 4, 8)),\n",
       "  (10.51455, (1, 3, 3)),\n",
       "  (10.362712, (1, 4, 2)),\n",
       "  (10.331228, (1, 3, 2)),\n",
       "  (9.836474, (4, 9, 5)),\n",
       "  (9.813205, (4, 5, 8)),\n",
       "  (9.546487, (4, 10, 4)),\n",
       "  (9.501915, (4, 8, 6)),\n",
       "  (9.265276, (4, 11, 5)),\n",
       "  (9.024993, (4, 7, 7)),\n",
       "  (8.871638, (4, 6, 7)),\n",
       "  (8.716935, (0, 4, 8)),\n",
       "  (8.675108, (4, 9, 6))],\n",
       " [(14.664563, (1, 3, 6)),\n",
       "  (12.218243, (1, 3, 4)),\n",
       "  (12.066067, (1, 3, 5)),\n",
       "  (11.853034, (1, 3, 7)),\n",
       "  (10.963835, (4, 3, 7)),\n",
       "  (10.242216, (1, 11, 4)),\n",
       "  (10.15063, (4, 6, 6)),\n",
       "  (10.149592, (4, 8, 5)),\n",
       "  (10.02931, (1, 11, 5)),\n",
       "  (9.914029, (4, 5, 6)),\n",
       "  (9.884069, (4, 4, 7)),\n",
       "  (9.840136, (4, 7, 5)),\n",
       "  (9.71972, (4, 10, 4)),\n",
       "  (9.673868, (4, 9, 4)),\n",
       "  (9.4589, (0, 3, 7)),\n",
       "  (9.257872, (4, 8, 4)),\n",
       "  (9.237775, (1, 4, 3)),\n",
       "  (9.144998, (4, 5, 7)),\n",
       "  (8.869293, (1, 4, 4)),\n",
       "  (8.831269, (0, 10, 5))],\n",
       " [(15.82171, (1, 4, 5)),\n",
       "  (15.716701, (1, 4, 4)),\n",
       "  (15.0590925, (1, 9, 9)),\n",
       "  (14.814839, (1, 9, 4)),\n",
       "  (14.55113, (1, 9, 8)),\n",
       "  (14.302644, (1, 4, 3)),\n",
       "  (14.064659, (4, 7, 7)),\n",
       "  (14.00155, (1, 9, 3)),\n",
       "  (13.664331, (1, 4, 6)),\n",
       "  (13.379918, (1, 3, 7)),\n",
       "  (13.368186, (4, 10, 5)),\n",
       "  (13.346981, (4, 4, 8)),\n",
       "  (13.32247, (4, 7, 6)),\n",
       "  (13.311966, (4, 6, 7)),\n",
       "  (13.224638, (4, 8, 7)),\n",
       "  (13.212799, (4, 8, 6)),\n",
       "  (13.198774, (4, 9, 5)),\n",
       "  (12.580459, (4, 9, 6)),\n",
       "  (12.509506, (4, 5, 7)),\n",
       "  (12.455315, (4, 8, 5))]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A group of neurons can be specified by the user to do the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_sample_id = 810\n",
    "neuron_list = [(1, 4, 4), (1, 4, 3), (1, 4, 5)]\n",
    "neuron_group = NeuronGroup(model.get_model(), layer_id, neuron_idx_list=neuron_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the closest image with respect to the neuron group specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 810, size of neuron group 3\n",
      "threshold: 0.4012274742126465, max in answer: 1.244203805923462, images run: 67\n",
      "threshold: 0.7033581137657166, max in answer: 1.01547372341156, images run: 131\n",
      "threshold: 0.9670814871788025, max in answer: 0.9958177804946899, images run: 195\n",
      "threshold: 1.2530744075775146, max in answer: 0.9958177804946899, images run: 260\n",
      "======================= NTA exited =======================\n",
      "[(-0.9958178, 9990), (-0.9594661, 8555), (-0.9563361, 6316), (-0.92077124, 6050), (-0.88487566, 6158), (-0.86679006, 5179), (-0.85618293, 3743), (-0.84050524, 60), (-0.83489597, 1935), (-0.81305367, 7960), (-0.78954655, 2187), (-0.73703915, 6366), (-0.6998202, 5326), (-0.6811, 4865), (-0.6809903, 6006), (-0.65254635, 4064), (-0.6416337, 7650), (-0.6308938, 3125), (-0.57279134, 822), (0.0, 810)]\n"
     ]
    }
   ],
   "source": [
    "top_k, exit_msg = model.answer_query_with_guarantee(layer_id, image_sample_id, 20, neuron_group)\n",
    "print(top_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_group = NeuronGroup(model.get_model(), layer_id, neuron_idx_list=[(5, 0, 2), (8, 2, 2), (2, 4, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 810, size of neuron group 3\n",
      "threshold: 0.03818821907043457, max in answer: 0.1384831666946411, images run: 427\n",
      "threshold: 0.20468735694885254, max in answer: 0.07035708427429199, images run: 851\n",
      "======================= NTA exited =======================\n",
      "[(-0.070357084, 4176), (-0.0684191, 4659), (-0.06708133, 3394), (-0.06519842, 9109), (-0.05986345, 2700), (-0.057710648, 554), (-0.052951217, 4042), (-0.045683503, 1100), (-0.04501462, 6053), (-0.04026103, 9618), (-0.039102912, 4421), (-0.03840089, 738), (-0.03818822, 812), (-0.03238964, 3431), (-0.026446223, 362), (-0.025786996, 924), (-0.024932742, 6871), (-0.020506978, 6075), (-0.0010017157, 2115), (0.0, 810)]\n"
     ]
    }
   ],
   "source": [
    "top_k, exit_msg = model.answer_query_with_guarantee(layer_id, image_sample_id, 20, neuron_group)\n",
    "print(top_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can construct indices for multiple layers, and the index constructed so far can be saved to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_index_map(\"saved_map\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saved indices can be reload back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_index_map(\"saved_map\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This part is aimed to show that the code also works with Tensorflow model, the process is similar, and user should create a super class shown in MnistVGG_api class, and use this class to do queries. The procedure is very similar comparing to using a Pytorch model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from utils import load_mnist_vgg_dataset_model\n",
    "from models.MnistVGG_api import MnistVGG\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 14:44:29.950431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-26 14:44:29.952892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-26 14:44:29.953203: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-26 14:44:29.953640: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-26 14:44:29.954584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-26 14:44:29.954978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-26 14:44:29.955421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-26 14:44:29.955887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-26 14:44:29.956187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-26 14:44:29.956483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-26 14:44:29.956769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6163 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_1', 'zero_padding2d', 'conv2d', 'batch_normalization', 'activation', 'conv2d_1', 'batch_normalization_1', 'activation_1', 'max_pooling2d', 'conv2d_2', 'batch_normalization_2', 'activation_2', 'conv2d_3', 'batch_normalization_3', 'activation_3', 'max_pooling2d_1', 'conv2d_4', 'batch_normalization_4', 'activation_4', 'conv2d_5', 'batch_normalization_5', 'activation_5', 'conv2d_6', 'batch_normalization_6', 'activation_6', 'max_pooling2d_2', 'conv2d_7', 'batch_normalization_7', 'activation_7', 'conv2d_8', 'batch_normalization_8', 'activation_8', 'conv2d_9', 'batch_normalization_9', 'activation_9', 'max_pooling2d_3', 'conv2d_10', 'batch_normalization_10', 'activation_10', 'conv2d_11', 'batch_normalization_11', 'activation_11', 'conv2d_12', 'batch_normalization_12', 'activation_12', 'max_pooling2d_4', 'flatten', 'dense', 'dropout', 'dense_1', 'dropout_1', 'dense_2', 'activation_13']\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = load_mnist_vgg_dataset_model()\n",
    "dataset = x_test\n",
    "dataset_labels = y_test\n",
    "del x_train\n",
    "del y_train\n",
    "model = MnistVGG(lib_file, dataset)\n",
    "all_layer_names = model.get_all_layer_names()\n",
    "print(all_layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = \"activation_12\"\n",
    "layer_id = all_layer_names.index(layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 1)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "print(dataset_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For demonstration only, no need for using DeepEverest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 14:44:31.708332: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8302\n",
      "2022-07-26 14:44:32.424525: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2, 2, 512)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "layer_result = model.get_layer_results_by_layer_id(layer_id)\n",
    "print(layer_result.shape)\n",
    "print(type(layer_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(2.2470694, (1, 1, 374)), (1.9390907, (0, 0, 113)), (1.9011351, (0, 0, 358)), (1.845798, (1, 0, 335)), (1.824193, (1, 1, 62)), (1.7726831, (1, 0, 182)), (1.7536618, (1, 1, 129)), (1.7496979, (0, 0, 95)), (1.7491616, (1, 0, 441)), (1.6753764, (1, 1, 177)), (1.6667678, (0, 0, 46)), (1.6587296, (0, 1, 340)), (1.6440464, (0, 1, 285)), (1.6398698, (1, 1, 428)), (1.6205434, (0, 1, 365)), (1.6141273, (0, 1, 461)), (1.5758126, (0, 0, 245)), (1.5589455, (0, 0, 45)), (1.5521427, (0, 1, 336)), (1.5128995, (0, 1, 379))]]\n"
     ]
    }
   ],
   "source": [
    "topk_activations = model.get_topk_activations_given_images([659], layer_name, 20)\n",
    "print(topk_activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify the results are correct (same) by brute force. This is for demonstration only, no need when using DeepEverest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2.2470694, (1, 1, 374)), (1.9390907, (0, 0, 113)), (1.9011351, (0, 0, 358)), (1.845798, (1, 0, 335)), (1.824193, (1, 1, 62)), (1.7726831, (1, 0, 182)), (1.7536618, (1, 1, 129)), (1.7496979, (0, 0, 95)), (1.7491616, (1, 0, 441)), (1.6753764, (1, 1, 177)), (1.6667678, (0, 0, 46)), (1.6587296, (0, 1, 340)), (1.6440464, (0, 1, 285)), (1.6398698, (1, 1, 428)), (1.6205434, (0, 1, 365)), (1.6141273, (0, 1, 461)), (1.5758126, (0, 0, 245)), (1.5589455, (0, 0, 45)), (1.5521427, (0, 1, 336)), (1.5128995, (0, 1, 379))]\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "image_samples = []\n",
    "for image_sample_id in [659]:\n",
    "    image_samples.append(dataset[image_sample_id])\n",
    "layer_result_image_samples = model.get_layer_result_by_layer_name(image_samples, layer_name)\n",
    "brute_force = []\n",
    "for i in range(layer_result_image_samples.shape[1]):\n",
    "    for j in range(layer_result_image_samples.shape[2]):\n",
    "        for k in range(layer_result_image_samples.shape[3]):\n",
    "            brute_force.append((layer_result_image_samples[0, i, j, k], (i, j, k)))\n",
    "sorted_array = sorted(brute_force, key=lambda k:k[0], reverse=True)\n",
    "print(sorted_array[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose top-3 neurons for image search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1, 374), (0, 0, 113), (0, 0, 358)]\n"
     ]
    }
   ],
   "source": [
    "from NeuronGroup import *\n",
    "image_sample_id = 659\n",
    "topk_activations_neurons = [x[1] for x in topk_activations[0]]\n",
    "neuron_group = NeuronGroup(model.get_model(), layer_id, neuron_idx_list=topk_activations_neurons[:3])\n",
    "print(topk_activations_neurons[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 659, size of neuron group 3\n",
      "threshold: 0.009087341837584972, max in answer: 1.0652905702590942, images run: 446\n",
      "threshold: 0.23611624538898468, max in answer: 0.7390373945236206, images run: 879\n",
      "threshold: 0.2542610764503479, max in answer: 0.7369700074195862, images run: 1320\n",
      "threshold: 0.466909259557724, max in answer: 0.6489895582199097, images run: 1707\n",
      "threshold: 0.5761297345161438, max in answer: 0.6489895582199097, images run: 2125\n",
      "threshold: 0.741787850856781, max in answer: 0.6489895582199097, images run: 2537\n",
      "======================= NTA exited =======================\n"
     ]
    }
   ],
   "source": [
    "top_k, exit_msg = model.answer_query_with_guarantee(layer_id, image_sample_id, 20, neuron_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query result (distance from the input image, image ids) array is:\n",
      "[(-0.64898956, 8043), (-0.6488446, 3073), (-0.6324043, 2915), (-0.63099045, 9505), (-0.6308887, 7985), (-0.61490345, 9664), (-0.57324046, 1941), (-0.570809, 9637), (-0.5610432, 1903), (-0.55843884, 3166), (-0.5519713, 468), (-0.53630835, 5649), (-0.5042943, 667), (-0.37808788, 7902), (-0.3767796, 3055), (-0.37318093, 5655), (-0.3371253, 4176), (-0.32670704, 4199), (-0.15818997, 3808), (0.0, 659)]\n",
      "termination: images run: 2537\n"
     ]
    }
   ],
   "source": [
    "print(\"The query result (distance from the input image, image ids) array is:\")\n",
    "print(top_k)\n",
    "print(exit_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify the results are correct (same) by brute force. This is for demonstration only, no need when using DeepEverest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2, 2, 512)\n",
      "[(1, 1, 374), (0, 0, 113), (0, 0, 358)]\n",
      "[2.247072  1.9390905 1.9011344]\n",
      "\n",
      "The query result (distance from the input image, image ids) array by brute force is:\n",
      "[(0.6489887, 8043), (0.64884716, 3073), (0.6324064, 2915), (0.6309891, 9505), (0.6308879, 7985), (0.6149021, 9664), (0.5732398, 1941), (0.5708099, 9637), (0.5610427, 1903), (0.5584397, 3166), (0.5519719, 468), (0.53630936, 5649), (0.50429475, 667), (0.3780878, 7902), (0.37678048, 3055), (0.37317818, 5655), (0.337125, 4176), (0.32670948, 4199), (0.15818849, 3808), (0.0, 659)]\n"
     ]
    }
   ],
   "source": [
    "print(layer_result.shape)\n",
    "print(topk_activations_neurons[:3])\n",
    "search_target = np.array([layer_result[659][(1, 1, 374)], layer_result[659][(0, 0, 113)], layer_result[659][(0, 0, 358)]])\n",
    "print(search_target)\n",
    "result_array = []\n",
    "for i in range(len(dataset)):\n",
    "    number = np.array([layer_result[i][(1, 1, 374)], layer_result[i][(0, 0, 113)], layer_result[i][(0, 0, 358)]])\n",
    "    distance = np.sqrt(np.sum((search_target - number) * (search_target - number)))\n",
    "    result_array.append((distance, i))\n",
    "result_array = sorted(result_array, key=lambda k: k[0], reverse=True)\n",
    "print()\n",
    "print(\"The query result (distance from the input image, image ids) array by brute force is:\")\n",
    "print(result_array[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = \"activation_10\"\n",
    "layer_id = all_layer_names.index(layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 659, size of neuron group 3\n",
      "threshold: 3.310506820678711, max in answer: 1.5521913766860962, images run: 443\n",
      "======================= NTA exited =======================\n"
     ]
    }
   ],
   "source": [
    "top_k, exit_msg = model.answer_query_with_guarantee(layer_id, image_sample_id, 20, neuron_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-1.5521914, 5831), (-1.5382272, 6105), (-1.5171522, 1156), (-1.473711, 7844), (-1.4282893, 5887), (-1.2838352, 2434), (-1.2651086, 1039), (-1.250756, 689), (-1.2400525, 9839), (-1.1397568, 726), (-1.1281551, 1173), (-1.1208655, 3213), (-1.1054935, 730), (-1.0767243, 746), (-1.0691105, 6188), (-1.0641898, 1581), (-0.98903173, 716), (-0.9283188, 4966), (-0.8697332, 649), (0.0, 659)]\n",
      "termination: images run: 443\n"
     ]
    }
   ],
   "source": [
    "print(top_k)\n",
    "print(exit_msg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
