{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T06:33:49.566203Z",
     "start_time": "2021-09-27T06:33:43.900312Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from utils import load_mnist_vgg_dataset_model, plot_mnist\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T06:33:43.900Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test, model = load_mnist_vgg_dataset_model()\n",
    "all_layer_names = [layer.name for layer in model.model.layers]\n",
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following preparation will be done during pre-processing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T06:33:43.901Z"
    }
   },
   "outputs": [],
   "source": [
    "x_test = x_test[:1000]\n",
    "y_test = y_test[:1000]\n",
    "dataset = x_test\n",
    "dataset_labels = y_test\n",
    "del x_train\n",
    "del y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure \"python setup_deepeverest_index.py build\" is run ahead of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T06:33:43.903Z"
    }
   },
   "outputs": [],
   "source": [
    "layer_name = \"activation_12\"\n",
    "layer_id = all_layer_names.index(layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T06:33:43.905Z"
    }
   },
   "outputs": [],
   "source": [
    "import ctypes\n",
    "lib_file = \"/Users/donghe/GoogleDrive/Projects/uwdb-deep-everest/index/build/lib.macosx-10.7-x86_64-3.7/deepeverst_index.cpython-37m-darwin.so\"\n",
    "index_lib = ctypes.CDLL(lib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T06:33:43.906Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from utils import *\n",
    "\n",
    "n_images = len(dataset)\n",
    "n_partitions= 32\n",
    "batch_size = 64\n",
    "ratio = 0.05\n",
    "bits_per_image = math.ceil(math.log(n_partitions, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T06:33:43.909Z"
    }
   },
   "outputs": [],
   "source": [
    "layer_result = get_layer_result_by_layer_id(model, dataset, layer_id, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T06:33:43.910Z"
    }
   },
   "outputs": [],
   "source": [
    "from DeepEverest import *\n",
    "\n",
    "rev_act, rev_idx_act, rev_bit_arr, rev_idx_idx, par_low_bound, par_upp_bound = construct_index(\n",
    "        index_lib=index_lib,\n",
    "        n_images=n_images,\n",
    "        ratio=ratio,\n",
    "        n_partitions=n_partitions,\n",
    "        bits_per_image=bits_per_image,\n",
    "        layer_result=layer_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indexes can be persisted to disk with np.save() or pickle.dump() for convenient re-use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T06:33:43.913Z"
    }
   },
   "outputs": [],
   "source": [
    "label_predicted = np.argmax(model.predict(dataset), axis=1)\n",
    "label_test = np.argmax(dataset_labels, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At query time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T06:33:43.914Z"
    }
   },
   "outputs": [],
   "source": [
    "misclassified_mask = label_predicted[:1000] != dataset_labels[:1000]\n",
    "np.where(misclassified_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T06:33:43.916Z"
    }
   },
   "outputs": [],
   "source": [
    "image_ids = [193, 412, 582, 659, 938]\n",
    "for image_id in image_ids:\n",
    "    prediction = np.argmax(model.predict(x_test[image_id]), axis=1).item()\n",
    "    plot_mnist(x_test, label_test, image_id, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T06:33:43.917Z"
    }
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "def get_topk_activations_given_images(model, dataset, image_ids, layer_name, k):\n",
    "    res = list()\n",
    "    image_samples = list()\n",
    "    for image_sample_id in image_ids:\n",
    "        image_samples.append(dataset[image_sample_id])\n",
    "    layer_result_image_samples = model.get_layer_result_by_layer_name(image_samples, layer_name)\n",
    "    for idx, image_sample_id in enumerate(image_ids):\n",
    "        heap = list()\n",
    "        for neuron_idx, activation in np.ndenumerate(layer_result_image_samples[idx]):\n",
    "            if len(heap) < k:\n",
    "                heapq.heappush(heap, (activation, neuron_idx))\n",
    "            elif (activation, neuron_idx) > heap[0]:\n",
    "                heapq.heapreplace(heap, (activation, neuron_idx))\n",
    "        res.append(sorted(heap, reverse=True))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T06:33:43.918Z"
    }
   },
   "outputs": [],
   "source": [
    "image_ids = [659]\n",
    "k_global = 20\n",
    "topk_activations = get_topk_activations_given_images(model, x_test, image_ids, layer_name, k_global)[0]\n",
    "topk_activations_neurons = [x[1] for x in topk_activations]\n",
    "topk_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T06:33:43.920Z"
    }
   },
   "outputs": [],
   "source": [
    "from NeuronGroup import *\n",
    "image_sample_id = 659\n",
    "neuron_group = NeuronGroup(model.model, layer_id, neuron_idx_list=topk_activations_neurons[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T06:33:43.921Z"
    }
   },
   "outputs": [],
   "source": [
    "top_k, exit_msg, is_in_partition_0, n_images_rerun = answer_query_with_guarantee(\n",
    "                                                        model, dataset, rev_act, rev_idx_act, rev_bit_arr, rev_idx_idx,\n",
    "                                                        par_low_bound, par_upp_bound, image_sample_id,\n",
    "                                                        neuron_group, k_global, n_partitions, bits_per_image,\n",
    "                                                        BATCH_SIZE=batch_size, batch_size=batch_size)\n",
    "top_k = sorted(top_k)\n",
    "top_k, exit_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T06:33:43.922Z"
    }
   },
   "outputs": [],
   "source": [
    "for neg_dist, image_id in top_k:\n",
    "    prediction = np.argmax(model.predict(x_test[image_id]), axis=1).item()\n",
    "    plot_mnist(x_test, label_test, image_id, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T06:33:43.923Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_2_as_7(image_id):\n",
    "    return label_predicted[image_id] == 7 and label_test[image_id] == 2\n",
    "\n",
    "def predict_7_as_7(image_id):\n",
    "    return label_predicted[image_id] == 7 and label_test[image_id] == 7\n",
    "\n",
    "def predict_2_as_2(image_id):\n",
    "    return label_predicted[image_id] == 2 and label_test[image_id] == 2\n",
    "\n",
    "def predict_7_as_2(image_id):\n",
    "    return label_predicted[image_id] == 2 and label_test[image_id] == 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T06:33:43.925Z"
    }
   },
   "outputs": [],
   "source": [
    "for neg_dist, image_id in top_k:\n",
    "    prediction = np.argmax(model.predict(x_test[image_id]), axis=1).item()\n",
    "    plot_mnist(dataset, label_test, image_id, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T06:33:43.926Z"
    }
   },
   "outputs": [],
   "source": [
    "seven_as_two = -1\n",
    "two_as_seven = -1\n",
    "two_as_two = -1\n",
    "seven_as_seven = -1\n",
    "for image_id in range(x_test.shape[0]):\n",
    "    if seven_as_two < 0 and predict_7_as_2(image_id):\n",
    "        seven_as_two = image_id\n",
    "    if two_as_seven < 0 and predict_2_as_7(image_id):\n",
    "        two_as_seven = image_id\n",
    "    if two_as_two < 0 and predict_2_as_2(image_id):\n",
    "        two_as_two = image_id\n",
    "    if seven_as_seven < 0 and predict_7_as_7(image_id):\n",
    "        seven_as_seven = image_id\n",
    "    if seven_as_two > 0 and two_as_seven > 0 and two_as_two > 0 and seven_as_seven > 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T06:33:43.927Z"
    }
   },
   "outputs": [],
   "source": [
    "image_ids = [two_as_two, seven_as_seven, two_as_seven, seven_as_two]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T06:33:43.928Z"
    }
   },
   "outputs": [],
   "source": [
    "for image_id in image_ids:\n",
    "    prediction = np.argmax(model.predict(x_test[image_id]), axis=1).item()\n",
    "    plot_mnist(x_test, label_test, image_id, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T06:33:43.929Z"
    }
   },
   "outputs": [],
   "source": [
    "k_global = 20\n",
    "topk_activations = get_topk_activations_given_images(model, x_test, image_ids, layer_name, k_global)\n",
    "topk_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T06:33:43.931Z"
    }
   },
   "outputs": [],
   "source": [
    "neuron_cnt = dict()\n",
    "for topk_activation in topk_activations:\n",
    "    for activation, neuron_idx in topk_activation:\n",
    "        if neuron_idx in neuron_cnt:\n",
    "            neuron_cnt[neuron_idx] += 1\n",
    "        else:\n",
    "            neuron_cnt[neuron_idx] = 1\n",
    "\n",
    "sorted_neurons = [(k, v) for k, v in sorted(neuron_cnt.items(), key=lambda item: item[1], reverse=True)]\n",
    "sorted_neurons_idx = [x[0] for x in sorted_neurons]\n",
    "sorted_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T06:33:43.932Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layer_id = all_layer_names.index(layer_name)\n",
    "neuron_group = NeuronGroup(model.model, layer_id, neuron_idx_list=sorted_neurons_idx[:1])\n",
    "top_k, exit_msg, is_in_partition_0, n_images_rerun = answer_query_with_guarantee(\n",
    "                                                        model, dataset, rev_act, rev_idx_act, rev_bit_arr, rev_idx_idx,\n",
    "                                                        par_low_bound, par_upp_bound, image_sample_id,\n",
    "                                                        neuron_group, k_global, n_partitions, bits_per_image,\n",
    "                                                        BATCH_SIZE=batch_size, batch_size=batch_size)\n",
    "top_k = sorted(top_k)\n",
    "for neg_dist, image_id in top_k:\n",
    "    prediction = np.argmax(model.predict(x_test[image_id]), axis=1).item()\n",
    "    plot_mnist(x_test, label_test, image_id, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T06:33:43.933Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_topk_images_given_neuron(rev_idx, idx_of_rev_idx, layer_id, neuron_idx, k):\n",
    "    key = (layer_id,) + neuron_idx\n",
    "    reverse_index = rev_idx[idx_of_rev_idx[key]]\n",
    "    res = list()\n",
    "    i = len(reverse_index.activations_with_idx) - 1\n",
    "    while i >= 0:\n",
    "        res.append(reverse_index.activations_with_idx[i][1])\n",
    "        i -= 1\n",
    "        if len(res) >= k:\n",
    "            break\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T06:33:43.935Z"
    }
   },
   "outputs": [],
   "source": [
    "layer_id = all_layer_names.index(layer_name)\n",
    "neuron_group = NeuronGroup(model.model, layer_id, neuron_idx_list=[(1, 0, 441)])\n",
    "top_k, exit_msg, is_in_partition_0, n_images_rerun = answer_query_with_guarantee(\n",
    "                                                        model, dataset, rev_act, rev_idx_act, rev_bit_arr, rev_idx_idx,\n",
    "                                                        par_low_bound, par_upp_bound, image_sample_id,\n",
    "                                                        neuron_group, k_global, n_partitions, bits_per_image,\n",
    "                                                        BATCH_SIZE=batch_size, batch_size=batch_size)\n",
    "top_k = sorted(top_k)\n",
    "\n",
    "for neg_dist, image_id in top_k:\n",
    "    prediction = np.argmax(model.predict(x_test[image_id]), axis=1).item()\n",
    "    plot_mnist(x_test, label_test, image_id, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T06:33:43.936Z"
    }
   },
   "outputs": [],
   "source": [
    "confusion_activations = [topk_activations[2], topk_activations[3]]\n",
    "neuron_cnt = dict()\n",
    "for topk_activation in confusion_activations:\n",
    "    for activation, neuron_idx in topk_activation:\n",
    "        if neuron_idx in neuron_cnt:\n",
    "            neuron_cnt[neuron_idx] += 1\n",
    "        else:\n",
    "            neuron_cnt[neuron_idx] = 1\n",
    "{k: v for k, v in sorted(neuron_cnt.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-27T06:33:43.937Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layer_id = all_layer_names.index(layer_name)\n",
    "neuron_group = NeuronGroup(model.model, layer_id, dimension_ranges=[(1, 2), (1, 2), (62, 130)])\n",
    "top_k, exit_msg, is_in_partition_0, n_images_rerun = answer_query_with_guarantee(\n",
    "                                                        model, dataset, rev_act, rev_idx_act, rev_bit_arr, rev_idx_idx,\n",
    "                                                        par_low_bound, par_upp_bound, image_sample_id,\n",
    "                                                        neuron_group, k_global, n_partitions, bits_per_image,\n",
    "                                                        BATCH_SIZE=batch_size, batch_size=batch_size)\n",
    "top_k = sorted(top_k)\n",
    "for neg_dist, image_id in top_k:\n",
    "    prediction = np.argmax(model.predict(x_test[image_id]), axis=1).item()\n",
    "    plot_mnist(x_test, label_test, image_id, prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
